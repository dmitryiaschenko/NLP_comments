{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\").fillna('missing')\n",
    "train = pd.read_csv(\"train.csv\").fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>I think its crap that the link to roggenbier i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>, 25 February 2010 (UTC) \\n\\n :::Looking it ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>==Current Position== \\n Anyone have confirmati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>this other one from 1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>== Reason for banning throwing == \\n\\n This ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>:: Wallamoose was changing the cited material ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>|blocked]] from editing Wikipedia.   |</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text\n",
       "0   00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1   0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2   00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3   00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4   00017695ad8997eb          I don't anonymously edit articles at all.\n",
       "5   0001ea8717f6de06  Thank you for understanding. I think very high...\n",
       "6   00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...\n",
       "7   000247e83dcc1211                   :Dear god this site is horrible.\n",
       "8   00025358d4737918  \" \\n Only a fool can believe in such numbers. ...\n",
       "9   00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...\n",
       "10  0002eadc3b301559  I think its crap that the link to roggenbier i...\n",
       "11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...\n",
       "12  0003806b11932181  , 25 February 2010 (UTC) \\n\\n :::Looking it ov...\n",
       "13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...\n",
       "14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...\n",
       "15  000634272d0d44eb  ==Current Position== \\n Anyone have confirmati...\n",
       "16  000663aff0fffc80                           this other one from 1897\n",
       "17  000689dd34e20979  == Reason for banning throwing == \\n\\n This ar...\n",
       "18  000834769115370c  :: Wallamoose was changing the cited material ...\n",
       "19  000844b52dee5f3f             |blocked]] from editing Wikipedia.   |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "concat_text = pd.concat([train_text, test_text]).str.lower()\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanData(text):\n",
    "    txt = str(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"\", text)\n",
    "    text = re.sub(r\"What's\", \"\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" USA \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\" uk \", \" England \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text) \n",
    "    text = re.sub(r\"n ig ger\", \"nigger\", text)\n",
    "    text = re.sub(r\"s hit\", \"shit\", text)\n",
    "    text = re.sub(r\"g ay\", \"gay\", text)\n",
    "    text = re.sub(r\"f ag got\", \"faggot\", text)\n",
    "    text = re.sub(r\"c ock\", \"cock\", text)\n",
    "    text = re.sub(r\"cu nt\", \"cunt\", text)\n",
    "    text = re.sub(r\"idi ot\", \"idiot\", text)\n",
    "    text = re.sub(r\"(f|ht)tp(s?)://\\\\S+\", \" \", text)\n",
    "    text = re.sub(r\"http\\\\S+\", \"\", text)\n",
    "    text = re.sub(r\"xml\\\\S+\", \"\", text)\n",
    "    text = re.sub(r\"(a|e)w+\\\\b\", \"\", text)\n",
    "    text = re.sub(r\"(y)a+\\\\b\", \"\", text)\n",
    "    text = re.sub(r\"(w)w+\\\\b\", \"\", text)\n",
    "    text = re.sub(r\"a?(ha)+\\\\b\", \"\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"i`m\", \"i am\", text)\n",
    "    text = re.sub(r\"it`s\", \"it is\", text)\n",
    "    text = re.sub(r\"i`ve\", \"i have\", text)\n",
    "    text = re.sub(r\"you`re\", \"you are\", text)\n",
    "    text = re.sub(r\"i`ve\", \"i have\", text)\n",
    "    text = re.sub(r\"didn`t\", \"did not\", text)\n",
    "    text = re.sub(r\"isn`t\", \"is not\", text)\n",
    "    text = re.sub(r\"we`re\", \"we are\", text)\n",
    "    text = re.sub(r\"you`ll\", \"you will\", text)\n",
    "    text = re.sub(r\"they`re\", \"they are\", text)\n",
    "    text = re.sub(r\"shouldn`t\", \"should not\", text)\n",
    "    text = re.sub(r\"he`s\", \"he has\", text)\n",
    "    text = re.sub(r\"wasn`t\", \"was not\", text)\n",
    "    text = re.sub(r\"won`t\", \"will not\", text)\n",
    "    text = re.sub(r\"wasn`t\", \"was not\", text)\n",
    "    text = re.sub(r\"haven`t\", \"have not\", text)\n",
    "    text = re.sub(r\"aren`t\", \"are not\", text)\n",
    "    text = re.sub(r\"f4ck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fu\", \"fuck you\", text)\n",
    "    text = re.sub(r\"fuckk\", \"fuck\", text)\n",
    "    text = re.sub(r\"fucka\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuuck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fucck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuc'k\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckn\", \"fuck\", text)\n",
    "    text = re.sub(r\"f'uck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckz\", \"fuck\", text)\n",
    "    text = re.sub(r\"fyuck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuck”\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckkk\", \"fuck\", text)\n",
    "    text = re.sub(r\"defuck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuck43\", \"fuck\", text)\n",
    "    text = re.sub(r\"nefuck\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckng\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckfu\", \"fuck\", text)\n",
    "    text = re.sub(r\"fucks\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuicky\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckum\", \"fuck\", text)\n",
    "    text = re.sub(r\"fuckee\", \"fuck\", text)\n",
    "    text = re.sub(r\"niggaz\", \"niggers\", text)\n",
    "    text = re.sub(r\"niggerz\", \"niggers\", text)\n",
    "    text = re.sub(r\"nigers\", \"niggers\", text)\n",
    "    text = re.sub(r\"niger\", \"nigger\", text)\n",
    "    text = re.sub(r\"niga\", \"nigger\", text)\n",
    "    text = re.sub(r\"nig\", \"nigger\", text)\n",
    "    text = re.sub(r\"nigor\", \"nigger\", text)\n",
    "    text = re.sub(r\"nigra\", \"nigger\", text)\n",
    "    text = re.sub(r\"nigre\", \"nigger\", text)\n",
    "    text = re.sub(r\"nigar\", \"nigger\", text)\n",
    "    text = re.sub(r\"niggor\", \"nigger\", text)\n",
    "    text = re.sub(r\"niggur\", \"nigger\", text)\n",
    "    text = re.sub(r\"nigga\", \"nigger\", text)\n",
    "    text = re.sub(r\"niggah\", \"nigger\", text)\n",
    "    text = re.sub(r\"niggar\", \"nigger\", text)\n",
    "    text = re.sub(r\"niggah\", \"nigger\", text)\n",
    "    text = re.sub(r\"niggress\", \"nigger\", text)\n",
    "    text = re.sub(r\"fag\", \"faggot\", text)\n",
    "    text = re.sub(r\"fagot\", \"faggot\", text)\n",
    "    text = re.sub(r\"fagt\", \"faggot\", text)\n",
    "    text = re.sub(r\"fagat\", \"faggot\", text)\n",
    "    text = re.sub(r\"f4gg0t\", \"faggot\", text)\n",
    "    text = re.sub(r\"fagg\", \"faggot\", text)\n",
    "    text = re.sub(r\"faggs\", \"faggots\", text)\n",
    "    text = re.sub(r\"fags\", \"faggots\", text)\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_text = concat_text.map(lambda x: cleanData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(sublinear_tf=True, \n",
    "                     strip_accents='unicode', \n",
    "                     analyzer='word', \n",
    "                     token_pattern=r'\\w{1,}', \n",
    "                     ngram_range=(1, 1), \n",
    "                     stop_words='english', \n",
    "                     max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.fit(concat_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text_features = tv.transform(train_text)\n",
    "test_text_features = tv.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctv = TfidfVectorizer(ngram_range=(1,5), \n",
    "                      strip_accents='unicode', \n",
    "                      use_idf=1, \n",
    "                      smooth_idf=1, \n",
    "                      sublinear_tf=1, \n",
    "                      analyzer='char', \n",
    "                      max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 5), norm='l2', preprocessor=None, smooth_idf=1,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=1,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=1,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctv.fit(concat_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_symb_features = ctv.transform(train_text)\n",
    "test_symb_features = ctv.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = hstack([train_text_features, train_symb_features])\n",
    "X_test = hstack([test_text_features, test_symb_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9791552305267389\n",
      "CV score for class severe_toxic is 0.9889143755861186\n",
      "CV score for class obscene is 0.9906488972577057\n",
      "CV score for class threat is 0.9894106458567586\n",
      "CV score for class insult is 0.9832730488920998\n",
      "CV score for class identity_hate is 0.9831076323725814\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "predictions = {'id': test['id']}\n",
    "for class_name in class_names:\n",
    "    y_train = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    cv_score = np.mean(cross_val_score(classifier, X_train, y_train, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    \n",
    "    predictions[class_name] = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98575163841533386"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict(predictions)\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
